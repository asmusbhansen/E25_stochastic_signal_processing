{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36b26176-b555-4cf7-b55d-7a594878aa3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import loadmat, wavfile\n",
    "\n",
    "# Get current notebook directory\n",
    "notebook_dir = os.getcwd()\n",
    "file_path = os.path.join(notebook_dir, \"test.mat\")\n",
    "speech_file_path = os.path.join(notebook_dir, \"speech.wav\")\n",
    "\n",
    "input = loadmat(file_path)\n",
    "a = input[\"a\"].flatten()\n",
    "x = input[\"x\"].flatten()\n",
    "\n",
    "speech_input = wavfile.read(speech_file_path)\n",
    "\n",
    "\n",
    "def to_float(x):\n",
    "    if x.dtype == np.int16:\n",
    "        return x.astype(np.float32) / 32768.0\n",
    "    if x.dtype == np.int32:\n",
    "        return x.astype(np.float32) / 2147483648.0\n",
    "    return x.astype(np.float32)\n",
    "\n",
    "speech_fs = speech_input[0]\n",
    "speech_data = speech_input[1]\n",
    "speech_data = to_float(speech_data)\n",
    "\n",
    "speech_data -= np.mean(speech_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc8c97ab-4e1d-40fb-9085-1431125183dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76f4c78b-ced3-4e70-b1b6-8438a4ad6cce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from scipy.signal import lfilter\n",
    "\n",
    "def lpc(x, k):\n",
    "\n",
    "    acf_values = acf(x, nlags=k+1)\n",
    "    \n",
    "    cov = np.zeros((k,k))\n",
    "    cross = np.zeros(k)\n",
    "    for i in range(k):\n",
    "        # We negate the rhs\n",
    "        cross[i] = -acf_values[i+1]\n",
    "        for j in range(k):\n",
    "            cov[i, j] = acf_values[np.abs(i-j)]\n",
    "\n",
    "    h = np.linalg.inv(cov) @ cross\n",
    "\n",
    "    # Here the analysis filter is used, which is the inverse of the synthesis filter.\n",
    "    # In the synthesis filter we add 1 in front of the filter \n",
    "    # We add [0] in front of the coeffecients, since we are using earlier samples to predict the current ([0]) sample\n",
    "    b = np.concatenate([[0], -h])  # numerator\n",
    "    a = [1]                        # denominator\n",
    "\n",
    "    x_hat = lfilter(b, a, x)\n",
    "\n",
    "    e = x - x_hat\n",
    "\n",
    "    mse = np.mean(e**2)\n",
    "    rmse = mse / np.var(x)\n",
    "\n",
    "    return e, h, x_hat, rmse\n",
    "\n",
    "e, h, x_hat, rmse  = lpc(x, k=15)\n",
    "\n",
    "plot_num = 1000\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x[:plot_num], label=\"x\")\n",
    "plt.plot(x_hat[:plot_num], label=\"x estimated\")\n",
    "plt.plot(e[:plot_num], label=\"error\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(a, label=\"a\")\n",
    "plt.plot(h, label=\"a estimated\")\n",
    "plt.legend()\n",
    "plt.title(\"Filter coeffecients\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "025dad82-2add-4310-a709-870f3e973d71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee3c2d11-1d8c-4324-91f9-5f2f58743fec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from scipy.signal.windows import hann\n",
    "\n",
    "# a)\n",
    "\n",
    "# Here we split the speech into chunks and place each chunk as a ROW in the matrix\n",
    "# This is much easier to work with in Python\n",
    "\n",
    "chunk_len = 240\n",
    "\n",
    "def chunks(x, N):\n",
    "    L = len(x)\n",
    "    M = L // N          # number of full chunks\n",
    "    return x[:M*N].reshape(M, N)\n",
    "\n",
    "speech_matrix = chunks(speech_data, chunk_len)\n",
    "\n",
    "# b)\n",
    "\n",
    "speech_energy = np.sum(speech_matrix**2, axis=1)\n",
    "\n",
    "speech_energy_argmax = np.argmax(speech_energy)\n",
    "\n",
    "plt.plot()\n",
    "plt.plot(np.arange(chunk_len)*(1/speech_fs), speech_matrix[speech_energy_argmax,:])\n",
    "plt.title(f\"Max energy chunk idx = {speech_energy_argmax}\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.sqrt(speech_energy))\n",
    "plt.title(\"Sqrt Speech Energy\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(speech_matrix.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "484decde-7e9a-4adb-b97b-ecf5c8acaf4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Class to mimic MatLab dsp.ZeroCrossingDetector()\n",
    "class ZeroCrossingDetector:\n",
    "    \"\"\"\n",
    "    Python equivalent of MATLAB dsp.ZeroCrossingDetector.\n",
    "    - Stateful: retains previous sign across frames\n",
    "    - Zero-handling matches MATLAB: zeros inherit previous nonzero sign\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.prev_sign = 0  # same as MATLAB initial state\n",
    "\n",
    "    def process(self, x):\n",
    "        x = np.asarray(x)\n",
    "\n",
    "        # compute sign\n",
    "        s = np.sign(x).astype(int)\n",
    "\n",
    "        # propagate sign through zeros, matching MATLAB behavior\n",
    "        for i in range(len(s)):\n",
    "            if s[i] == 0:\n",
    "                s[i] = self.prev_sign\n",
    "            else:\n",
    "                break  # once a nonzero sample is found, no need for more\n",
    "\n",
    "        # count zero-crossings including transition from previous frame\n",
    "        full = np.concatenate([[self.prev_sign], s])\n",
    "        zc = np.count_nonzero(np.diff(full))\n",
    "\n",
    "        # update internal state: last nonzero sign if possible\n",
    "        if np.any(s != 0):\n",
    "            self.prev_sign = s[s != 0][-1]\n",
    "\n",
    "        return zc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb69770e-6077-4041-b718-a5ed0154eb3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# c)\n",
    "\n",
    "# I could not get the zero crossing method to work reliable so I used energy for voiced detection.\n",
    "\n",
    "zc_threshold = chunk_len // 2\n",
    "energy_threshold = 0.025\n",
    "\n",
    "zcd = ZeroCrossingDetector()\n",
    "\n",
    "speech_zc = np.array([zcd.process(speech_matrix[i, :]) for i in range(speech_matrix.shape[0])])\n",
    "#speech_voiced = [1 if speech_zc[i] < zc_threshold else 0 for i in range(len(speech_zc))]\n",
    "speech_voiced_ = np.array([np.ones(chunk_len) if speech_energy[i] > energy_threshold**2 else np.zeros(chunk_len) for i in range(len(speech_energy))])\n",
    "speech_voiced = np.array([1 if speech_energy[i] > energy_threshold**2 else 0 for i in range(len(speech_energy))])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(speech_matrix.ravel(), label=\"Speech\")\n",
    "plt.plot(speech_voiced_.ravel()/10, label=\"Speech Voiced\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8ba451e-e2bd-4325-ac14-518cdcc1836e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# d)\n",
    "\n",
    "excitation = []\n",
    "coefs = []\n",
    "predicted = []\n",
    "\n",
    "for i in range(speech_matrix.shape[0]):\n",
    "\n",
    "    x_in = speech_matrix[i, :]\n",
    "    e, h, x_hat, rmse_  = lpc(x_in, k=15)\n",
    "    excitation += [e]\n",
    "    coefs += [h]\n",
    "    predicted += [x_hat]\n",
    "\n",
    "# Create arrays\n",
    "excitation = np.array(excitation)\n",
    "coefs = np.array(coefs)\n",
    "predicted = np.array(predicted)\n",
    "rmse = np.array(rmse)\n",
    "\n",
    "start = 4400\n",
    "stop = 5000\n",
    "\n",
    "idx = speech_energy_argmax\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(speech_matrix.ravel()[start:stop], label=\"Signal\")\n",
    "plt.plot(predicted.ravel()[start:stop], label=\"Predicted\")\n",
    "plt.plot(excitation.ravel()[start:stop], label=\"Excitation\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a304098c-d8f0-47b3-bf46-2a0d2ae5ce6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# e)\n",
    "\n",
    "speech_matrix = speech_matrix.astype(np.float64)\n",
    "coefs = coefs.astype(np.float64)\n",
    "\n",
    "org_bytes = speech_matrix.nbytes\n",
    "comp_bytes = coefs.nbytes\n",
    "\n",
    "print(f\"Original signal bytes: {org_bytes}, compressed bytes: {comp_bytes}, compression ration {org_bytes/comp_bytes:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4697431-9449-4091-8523-5fd0a006f2f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### 1.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1098cf9-5db1-478d-b87c-8b2eec79ba3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# a, b and c\n",
    "\n",
    "def UV_exicte(N):\n",
    "    return np.random.normal(0, 1, N)\n",
    "\n",
    "def V_exicte(N, pitch_hz, fs):\n",
    "    \n",
    "    # Calculate sample spacing between pitches\n",
    "    excitation_delta_time = 1/pitch_hz\n",
    "    sample_delta_time = 1/fs\n",
    "\n",
    "    # We calculate the delta samples needed for the pitch\n",
    "    Np = int(np.round(excitation_delta_time / sample_delta_time))\n",
    "\n",
    "    exc = np.zeros(N, dtype=float)\n",
    "\n",
    "    # Find impulse indices\n",
    "    impulse_indices = np.arange(0, N, Np)\n",
    "\n",
    "    # Set impulse indices to 1\n",
    "    exc[impulse_indices] = 1\n",
    "\n",
    "    return exc\n",
    "\n",
    "def synth(exc, h):\n",
    "    a_full = np.concatenate([[1], h])\n",
    "    b = [1]  # all-pole filter\n",
    "    x_synth = lfilter(b, a_full, exc)\n",
    "    return x_synth\n",
    "\n",
    "# Determines which exication to use\n",
    "def get_excite(idx, speech_voiced):\n",
    "    if speech_voiced[idx] == 1:\n",
    "        return V_exicte(chunk_len, pitch_hz=133, fs=speech_fs)\n",
    "    else:\n",
    "        return UV_exicte(chunk_len)\n",
    "    \n",
    "# Create excitation matrix\n",
    "speech_exication = np.array([get_excite(idx=i, speech_voiced=speech_voiced) for i in range(speech_voiced.shape[0])])\n",
    "print(speech_exication.shape)\n",
    "\n",
    "# Create speech synth matrix\n",
    "speech_synth = np.array([synth(exc=speech_exication[i], h=coefs[i, :]) for i in range(speech_exication.shape[0])])\n",
    "\n",
    "#Rescale energy\n",
    "speech_synth = (speech_synth.T * np.sqrt(speech_energy/np.sum(speech_synth**2, axis=1))).T\n",
    "\n",
    "#excitation_ = get_excite(idx=speech_energy_argmax, speech_voiced=speech_voiced)  \n",
    "#print(excitation_.shape)\n",
    "#x_synth = synth(exc=excitation_, h=coefs[speech_energy_argmax, ])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(speech_synth[speech_energy_argmax, :], label=\"Speech synth\")\n",
    "plt.plot(speech_matrix[speech_energy_argmax, :], label=\"Speech Original\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(speech_synth.ravel(), label=\"Speech synth\")\n",
    "plt.plot(speech_matrix.ravel(), label=\"Speech Original\")\n",
    "plt.legend()\n",
    "\n",
    "int16_audio = np.int16(speech_synth.ravel() * 32767)\n",
    "wavfile.write(\"speech_synth.wav\", speech_fs, int16_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a013d1e-de09-4528-8ca6-a1167c4da459",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "There is a clear difference between the original and synthesized signal, but the harmonics seems to match up. The quality of the signal is not the best, it sounds like a robot speaking but the speech can be understood.\n",
    "\n",
    "To make the speech easier to understand, a better voiced detector and some overlaps in the speech frames could be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "caf547d6-4913-4f99-9898-baaf9ba55a9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4566bea0-82e4-4703-9dd6-0578f969458a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "The LS estimator in closed form is\n",
    "\n",
    "$$\\hat{\\boldsymbol{\\theta}} = (\\mathbf{H}^T \\mathbf{H})^{-1} \\mathbf{H}^T \\mathbf{y}$$\n",
    "\n",
    "Where \\\\(\\mathbf{H}\\\\) is the design matrix with rows \\\\(\\mathbf{h_1}=[1, x_1, x_1^2]\\\\) to \\\\(\\mathbf{h_N}=[1, x_N, x_N^2]\\\\) for \\\\(M=3\\\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7513c8b-1c89-4b25-931e-ee5ff604f2c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 100\n",
    "\n",
    "i = np.arange(1,N+1)\n",
    "\n",
    "x = np.sin(2*np.pi*i/N)\n",
    "\n",
    "w = np.random.normal(0, 0.2, N)\n",
    "\n",
    "y = x + w\n",
    "\n",
    "train_samples = 10\n",
    "M = 3\n",
    "\n",
    "train_idx = np.random.randint(low=0, high=N, size=train_samples)\n",
    "\n",
    "y_train = y[train_idx]\n",
    "x_train = x[train_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac7a1c03-14d7-4aad-8946-ad164e03e3b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c560f91-5d47-4f40-891c-9ce43e76cda8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "H = np.zeros((N, M+1))\n",
    "\n",
    "for t in range(N):\n",
    "    for m in range(M+1):\n",
    "        H[t, m] = i[t]**m\n",
    "\n",
    "H_train = H[train_idx, :]\n",
    "\n",
    "theta_hat = np.linalg.pinv(H_train) @ x_train\n",
    "\n",
    "x_hat = H @ theta_hat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b1a4800-1107-4b9b-af05-ffed84197196",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b62dd6e3-c4c5-4930-bd11-a0b8885fab26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(x, label=\"x\")\n",
    "plt.plot(y, label=\"y\")\n",
    "plt.plot(x_hat, label=\"x_hat\")\n",
    "plt.plot(x-x_hat, label=\"Error\")\n",
    "plt.legend()\n",
    "plt.title(f\"M={M}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28e9e874-a034-48cb-a664-7afed9d13446",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The estimated model is very close to the ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7115e876-0141-4d97-9d0e-6cddd5ec2d65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.4\n",
    "\n",
    "Here 10 samples is used for training on a 10 order polynomial. It is seen that we're overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8138a9bc-7714-45c7-b0ea-04e8d9475801",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(x, label=\"x\")\n",
    "plt.plot(y, label=\"y\")\n",
    "plt.plot(x_hat, label=\"x_hat\")\n",
    "plt.plot(x-x_hat, label=\"Error\")\n",
    "plt.legend()\n",
    "plt.title(f\"M={M}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "192b15b4-2b06-4383-be3f-c8861be23368",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.5\n",
    "\n",
    "If we increase the number of training samples to 50, we're decreasing overfit, but the model is still not as good as when M=3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65339bb3-2a8c-4572-b30f-b462a3933a06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(x, label=\"x\")\n",
    "plt.plot(y, label=\"y\")\n",
    "plt.plot(x_hat, label=\"x_hat\")\n",
    "plt.plot(x-x_hat, label=\"Error\")\n",
    "plt.legend()\n",
    "plt.title(f\"M={M}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "assignment4",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
