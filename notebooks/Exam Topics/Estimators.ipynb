{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f68f400-8158-4633-b462-f59da8101152",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Estimators\n",
    "\n",
    "#### Estimation examples\n",
    "\n",
    "**Parameter estimation** - Estimating a single parameter, for example DC level in noisy signal, or time-of-flight in radar signal\n",
    "\n",
    "**Randon Variable Estimation** - Estimation of one inaccessible RV which is correlated to another. For example, height/weight, temperature/icecream sales.\n",
    "\n",
    "**Signal estimation** - Forecasting or denoising\n",
    "\n",
    "#### Estimator model\n",
    "\n",
    "An estimator is a rule/function that maps a realization \\\\([x_0, x_1,..,x_{N-1}]\\\\) into some estimate \\\\(\\theta\\\\)\n",
    "\n",
    "$$\n",
    "\\widehat{\\mathbf{\\theta}}=g(x_0, x_1,..,x_{N-1})\n",
    "$$\n",
    "\n",
    "- Use data\n",
    "- Have an objective function\n",
    "- Have a model\n",
    "- Maps a realization of data to the estimate \\\\(\\theta\\\\)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1bb2b48-beac-4ca4-9d70-fe827b8b7413",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Estimator Evaluation\n",
    "\n",
    "##### Estimator Bias\n",
    "\n",
    "The estimator bias is defined as\n",
    "\n",
    "$$\n",
    "Bias = \\mathbb{E}[\\theta-\\widehat{\\theta}]\n",
    "$$\n",
    "\n",
    "For an estimator to be unbiased, on average it has to be equal to the true value\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[\\widehat{\\theta}]=\\theta\n",
    "$$\n",
    "\n",
    "##### Estimator Variance\n",
    "\n",
    "An estimator is just a mapping of one or several random variables and is a random variable in itself.\n",
    "\n",
    "##### Examples\n",
    "\n",
    "Esimtate DC level in white noise. Signal model \\\\(x_n=A+w_n\\\\) where \\\\(w_n\\\\) is guassian with zero mean and variance \\\\(\\sigma_w^2\\\\).\n",
    "\n",
    "The probability distribution will be\n",
    "\n",
    "$$\n",
    "f(x;A)=\\frac{1}{\\sqrt{2\\pi\\sigma_w^2}} e^{\\frac{-(x-A)^2}{2\\sigma_w^2}}\n",
    "$$\n",
    "\n",
    "\n",
    "If we define our estimator of A to be \\\\(\\widehat{A}=x_0\\\\) then we can calculate the bias and variance\n",
    "\n",
    "$$\n",
    "Bias(\\widehat{A})=\\mathbb{E}[A-\\widehat{A}]=\\mathbb{E}[A]-\\mathbb{E}[\\widehat{A}]=\\mathbb{E}[A]-\\mathbb{E}[x_0]=A-A=0\n",
    "$$\n",
    "\n",
    "Since \\\\(\\\\mathbb{E}[A]=A\\\\) and \\\\(\\mathbb{E}[x_0]=A\\\\) \n",
    "\n",
    "We define the variance as \n",
    "\n",
    "$$\n",
    "Var(\\widehat{A})=Var(x_0)=\\sigma_w^2\n",
    "$$\n",
    "\n",
    "If instead the estimator was \\\\(\\widehat{A}=\\frac{1}{N}\\sum_{i=0}^{N-1}x_i\\\\)\n",
    "\n",
    "$$\n",
    "Var(\\widehat{A})=Var(\\frac{1}{N}\\sum_{i=0}^{N-1}x_i)=\\frac{1}{N^2}N\\sigma_w^2=\\frac{\\sigma_w^2}{N}\n",
    "$$\n",
    "\n",
    "Because of the additivie property of the variance \\\\(Var(A+B)=Var(A)+Var(B)\\\\)\n",
    "\n",
    "##### Minumum Variance Unbiased Estimator\n",
    "\n",
    "The minimum variance estimator, is the unbiased estimator with the least variance.\n",
    "\n",
    "The minimum variance is determined by the \"sharpness\" of the PDF. The more the PDF depends on the unknown paramter \\\\(\\theta\\\\), the more accurate the estimator will be. \n",
    "\n",
    "The expected sharpness is defined as below. We take the negative, since the double differentiation tend to be negative at the peak(The first difference goes from zero to negative).\n",
    "\n",
    "$$\n",
    "I(\\theta) = -E_{\\mathbf{x}} \\left[ \\frac{\\partial^2 \\ln p[\\mathbf{x}; \\theta]}{\\partial \\theta^2} \\right]\n",
    "$$\n",
    "\n",
    "The effeciency of the estimator can be evaluated by how close we come to the inverse of the information matrix. Hence we want \\\\(Var(\\widehat{\\theta})=I(\\widehat{\\theta})^{-1}\\\\).\n",
    "The higher information, the lower variance we expect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "540afbca-3877-4e1b-8ea1-6e912cae9d4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Estimator classes\n",
    "\n",
    "We have the following estimator classes:\n",
    "- Maximum Likelihood(ML)\n",
    "- Maximum A Posteriori(MAP)\n",
    "- Minimum Mean Square Estimator\n",
    "- Least Squares Estimator\n",
    "\n",
    "##### Terms\n",
    "\n",
    "Prior distribution - The believed distribution of parameter \\\\(\\theta\\\\) before any data is observed.\n",
    "\n",
    "Posteriori distribution . The updated knowledge about \\\\(\\theta\\\\) after data has been observed.\n",
    "\n",
    "##### Maximum Likelihood\n",
    "\n",
    "The maximum likelihood estimator tries to maximize the likelihood of observing the data, given som parameter \\\\(\\theta\\\\).\n",
    "\n",
    "**Model** - Data is a realization of a random process with unknown paramter \\\\(\\theta\\\\)\n",
    "\n",
    "***Objective**\n",
    "\n",
    "$$\n",
    "\\widehat{\\theta}=\\argmax_{\\theta}f(\\mathbf{y}|\\theta) \n",
    "$$\n",
    "\n",
    "Needs **oberserved data** and **conditional distribution of data \\\\(f(y|\\theta)\\\\)**\n",
    "\n",
    "Is always asymptotically unbiased and efficient.\n",
    "\n",
    "##### Maximum A Posteriori\n",
    "\n",
    "Maximum a posteriori tries to maximize the posteriori using Bayes theorem \\\\(f(\\theta \\mid y) \\propto f(y \\mid \\theta)f(\\theta)\\\\).\n",
    "\n",
    "**Model** - Combines the likelihood(As in ML) with the prior(Distribution of \\\\(\\theta\\\\)) and finds the peak of the posteriori distribution.\n",
    "\n",
    "**Objective**\n",
    "\n",
    "$$\n",
    "\\widehat{\\theta}=\\argmax_{\\theta} f(y \\mid \\theta)f(\\theta)\n",
    "$$\n",
    "\n",
    "Needs **oberserved data**, **conditional distribution of data \\\\(f(y|\\theta)\\\\)** and **distribution of parameter \\\\(f(\\theta)\\\\)**\n",
    "\n",
    "##### Minimum Mean Square\n",
    "\n",
    "Here we minimize the expected mean square of a parameter, given some observed data\n",
    "\n",
    "**Model** - Combines likelihood and prior to find the \"average\" value. For a Gaussian(Or any other symmetric and unimodal distribution) MMSE = MAP.\n",
    "\n",
    "**Objective**\n",
    "\n",
    "$$\n",
    "\\widehat{\\theta} = \\argmin_{\\widehat{\\theta}} E[(\\theta - \\widehat{\\theta})^2 \\mid y]\n",
    "$$\n",
    "\n",
    "Needs **oberserved data**, **joint distribution of data and parameter** \\\\(f(\\theta,y)\\\\)\n",
    "\n",
    "##### Least Squares\n",
    "\n",
    "**Model** - We use the linear model \\\\(\\mathbf{y} = \\mathbf{H}\\theta + \\epsilon\\\\) where it is assumed that the paramter is linearly related to the observed data but no underlying probability distribution of the noise is asumed.\n",
    "\n",
    "**Objective**\n",
    "\n",
    "$$\n",
    "\\widehat{\\theta}=\\argmin_{\\theta} \\(\\mathbf{y} - \\mathbf{H}\\theta\\)^T(\\mathbf{y} - \\mathbf{H}\\theta\\)\n",
    "$$\n",
    "\n",
    "Solution \\\\(\\widehat{\\theta}=(\\mathbf{H}^T\\mathbf{H})^{-1}\\mathbf{H}^T\\mathbf{y}\\\\)\n",
    "\n",
    "Needs **Observed data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0cd17de-a4a1-4fac-ad92-ebcea91774d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### Fitting a straight line to data\n",
    "\n",
    "We have some data which we assume fits the model \\\\(y_n=ax_n+b+w_n\\\\) where \\\\(w_n\\\\) is independent gaussian noise with zero mean and variance \\\\(\\sigma_w^2\\\\)\n",
    "\n",
    "##### Least squares\n",
    "\n",
    "We have the coeffecient matrix \\\\(\\theta=[a, b]\\\\) we are trying to estimate.\n",
    "\n",
    "The design matrix is \\\\(\\mathbf{H}=[\\mathbf{h}_1, \\mathbf{h}_2,..,\\mathbf{h}_N]^T\\\\) where \\\\(\\mathbf{h}_1=[1, x_1]\\\\) and \\\\(\\mathbf{y}=[y_1, y_2,..,y_N]^T\\\\)\n",
    "\n",
    "##### Maximum likelihood\n",
    "\n",
    "The likelihood function of the darta can be expressed as\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x}|a, b, \\sigma_w^2)=\\prod_{i=1}^N\\frac{1}{\\sqrt{2\\pi \\sigma_w^2}}e^{-()}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Estimators",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
